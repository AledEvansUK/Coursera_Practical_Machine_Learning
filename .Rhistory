tidyControl <- trainControl(method = "cv", number = 6)
modelKNN = train(classe ~., data=tidyTraining, method="knn", metric="Kappa", trControl=tidyControl(method=CV), number =5, verbose=FALSE)
tidyControl <- trainControl(method = "cv", number = 6)
modelKNN = train(classe ~., data=tidyTraining, method="knn", metric="Kappa", trControl=tidyControl, number =5, verbose=FALSE)
predictKNN <- predict(modelKNN, newdata=tidyTesting)
confMatxKNN <-confusionMatrix(predictKNN, tidyTesting$classe)
confMatxKNN
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=5, fig.height=4)
options(width = 120)
# Chunk 2
library(plyr)
library(caret)
library(rpart)
library(randomForest)
library(gbm)
library(survival)
library(splines)
library(parallel)
library(e1071)
# Chunk 3
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
dataTesting <- read.csv("pml-testing.csv", header=TRUE)
# Chunk 4
dim(dataTraining)
# Chunk 5
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dataTraining <- dataTraining[, naVar==FALSE]
dim(dataTraining)
# Chunk 6
library(caret)
nearZero <- nearZeroVar(dataTraining)
dataTraining <- dataTraining[, -nearZero]
dim(dataTraining)
# Chunk 7
set.seed(425)
dataTraining2 <- createDataPartition(y=dataTraining$classe,p=0.7, list=FALSE)
tidyTraining <- dataTraining[dataTraining2,]
tidyTesting <- dataTraining[-dataTraining2,]
dim(tidyTraining)
dim(tidyTesting)
# Chunk 8: KNN
tidyControl <- trainControl(method = "cv", number = 6)
modelKNN = train(classe ~., data=tidyTraining, method="knn", metric="Kappa", trControl=tidyControl, number =5, verbose=FALSE)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=5, fig.height=4)
options(width = 120)
# Chunk 2
library(plyr)
library(caret)
library(rpart)
library(randomForest)
library(gbm)
library(survival)
library(splines)
library(parallel)
library(e1071)
# Chunk 3
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
dataTesting <- read.csv("pml-testing.csv", header=TRUE)
# Chunk 4
dim(dataTraining)
# Chunk 5
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dataTraining <- dataTraining[, naVar==FALSE]
dim(dataTraining)
# Chunk 6
library(caret)
nearZero <- nearZeroVar(dataTraining)
dataTraining <- dataTraining[, -nearZero]
dim(dataTraining)
# Chunk 7
set.seed(425)
dataTraining2 <- createDataPartition(y=dataTraining$classe,p=0.7, list=FALSE)
tidyTraining <- dataTraining[dataTraining2,]
tidyTesting <- dataTraining[-dataTraining2,]
dim(tidyTraining)
dim(tidyTesting)
# Chunk 8: KNN
tidyControl <- trainControl(method = "cv", number = 6)
modelKNN = train(classe ~., data=tidyTraining, method="knn", metric="Kappa", trControl=tidyControl, number =5, verbose=FALSE)
modelKNN$finalModel
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=5, fig.height=4)
options(width = 120)
# Chunk 2
library(plyr)
library(caret)
library(rpart)
library(randomForest)
library(gbm)
library(survival)
library(splines)
library(parallel)
library(e1071)
# Chunk 3
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
dataTesting <- read.csv("pml-testing.csv", header=TRUE)
# Chunk 4
dim(dataTraining)
# Chunk 5
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dataTraining <- dataTraining[, naVar==FALSE]
dim(dataTraining)
# Chunk 6
library(caret)
nearZero <- nearZeroVar(dataTraining)
dataTraining <- dataTraining[, -nearZero]
dim(dataTraining)
# Chunk 7
set.seed(425)
dataTraining2 <- createDataPartition(y=dataTraining$classe,p=0.7, list=FALSE)
tidyTraining <- dataTraining[dataTraining2,]
tidyTesting <- dataTraining[-dataTraining2,]
dim(tidyTraining)
dim(tidyTesting)
# Chunk 8: KNN
tidyControl <- trainControl(method = "cv", number = 6)
modelKNN = train(classe ~., data=tidyTraining, method="knn", trControl=tidyControl)
modelKNN$finalModel
dim(dataTraining)
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dim(naVar)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=5, fig.height=4)
options(width = 120)
# Chunk 2
library(plyr)
library(caret)
library(rpart)
library(randomForest)
library(gbm)
library(survival)
library(splines)
library(parallel)
library(e1071)
# Chunk 3
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
dataTesting <- read.csv("pml-testing.csv", header=TRUE)
dim(dataTraining)
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dim(naVar)
dim(dataTraining)
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
str(dataTraining)
dim(dataTraining)
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
str(dataTraining, list.len=50)
dim(dataTraining)
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
str(dataTraining, list.len=40)
dim(dataTraining)
str(dataTraining, list.len=40)
# set control
tidyControl <- trainControl(method = "cv", number = 6)
# train KNN model
modelKNN = train(classe ~., data=tidyTraining, method="knn", metric="Kappa",  trControl=tidyControl,  verbose=FALSE)
predictTesting <- predict(modelGBM, newdata=dataTesting))
predictTesting
predictTesting <- predict(modelGBM, newdata=dataTesting)
predictTesting
# use "dim" and "str" to give brief overveiw of dataset structure
dim(dataTraining)
str(dataTraining, list.len=40)
dim(dataTesting)
str(dataTesting, list.len=40)
# Remove varables with NA greater than 90%. "dim" to review datset structure
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dataTraining <- dataTraining[, naVar==FALSE]
dim(dataTraining)
naVar2 <- sapply(dataTesting, function(x) mean(is.na(x))) > 0.90
dataTesting <- dataTesting[, naVar==FALSE]
dim(dataTesting)
```
# remove variables with Near Zero Variance
nearZero <- nearZeroVar(dataTraining)
dataTraining <- dataTraining[, -nearZero]
dim(dataTraining)
# repeat for testing dataset
nearZero2 <- nearZeroVar(dataTesting)
dataTesting <- dataTesting[, -nearZero2]
dim(dataTesting)
predictTesting <- predict(modelGBM, newdata=dataTesting)
predictTesting
predictTesting2 <- predict(modelKNN, newdata=dataTesting)
predictTesting2
predictTesting2 <- predict(modelKNN, newdata=dataTesting)
predictTesting2
predictTesting2 <- predict(modelKNN, dataTesting)
predictTesting2
predictTesting2 <- predict(modelKNN, testing)
predictTesting2
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
testing <- read.csv("pml-testing.csv", header=TRUE)
predictTesting2 <- predict(modelKNN, testing)
predictTesting2
# use "dim" and "str" to give brief overveiw of dataset structure
dim(dataTraining)
str(dataTraining, list.len=40)
dim(dataTesting)
str(dataTesting, list.len=40)
# use "dim" and "str" to give brief overveiw of dataset structure
dim(dataTraining)
str(dataTraining, list.len=40)
dim(dataTesting)
str(testing, list.len=40)
# use "dim" and "str" to give brief overveiw of dataset structure
dim(dataTraining)
str(dataTraining, list.len=40)
dim(testing)
str(testing, list.len=40)
predictTesting <- predict(modelGBM, testing)
predictTesting
predictTesting2 <- predict(modelKNN, testing)
predictTesting2
predictTesting <- predict(modelGBM, testing)
print(as.data.frame(predictTesting)
predictTesting <- predict(modelGBM, testing)
print(as.data.frame(predictTesting))
# use "dim" and "str" to give brief overveiw of dataset structure
dim(dataTraining)
str(dataTraining, list.len=160)
dim(testing)
str(testing, list.len=160)
# use "dim" and "str" to give brief overveiw of dataset structure
dim(dataTraining)
str(dataTraining, list.len=160)
dim(testing)
str(testing, list.len=160)
print(testing)
# use "dim" and "str" to give brief overveiw of dataset structure
dim(dataTraining)
str(dataTraining, list.len=160)
dim(testing)
str(testing, list.len=160)
print(dataTraining)
View(dataTraining)
View(dataTraining)
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
testing <- read.csv("pml-testing.csv", header=TRUE)
View(dataTraining2)
View(dataTraining)
View(dataTraining)
# use "dim" and "str" to give brief overveiw of dataset structure
dim(dataTraining)
str(dataTraining, list.len=160)
dim(testing)
str(testing, list.len=160)
print(testing)
# Remove varables with NA greater than 90%. "dim" to review datset structure
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dataTraining <- dataTraining[, naVar==FALSE]
dim(dataTraining)
naVar2 <- sapply(testing, function(x) mean(is.na(x))) > 0.90
testing <- testing[, naVar==FALSE]
dim(testing)
set.seed(425)
dataTraining2 <- createDataPartition(y=dataTraining$classe,p=0.7, list=FALSE)
tidyTraining <- dataTraining[dataTraining2,]
tidyTesting <- dataTraining[-dataTraining2,]
dim(tidyTraining)
dim(tidyTesting)
predictTesting <- predict(modelGBM, newdata=testing)
print(as.data.frame(predictTesting))
predictTest <- predict(modelGBM, newdata=testing)
print(as.data.frame(predictTest))
predictTesting3 <- predict(modelRandomF, testing)
print(as.data.frame(predictTesting3))
predictTesting3 <- predict(modelRandomF, newdata=testing)
print(as.data.frame(predictTesting3))
library(plyr)
library(caret)
library(rpart)
library(randomForest)
library(gbm)
library(survival)
library(splines)
library(parallel)
library(e1071)
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
testing <- read.csv("pml-testing.csv", header=TRUE)
predictTesting3 <- predict(modelRandomF, newdata=testing)
print(as.data.frame(predictTesting3))
predictTesting2 <- predict(modelKNN, testing)
print(as.data.frame(predictTesting2))
predictTest <- predict(modelGBM, newdata=testing)
print(as.data.frame(predictTest))
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
testing <- read.csv(url(urlTesting))
dim(testing)
str(testing, list.len=160)
print(testing)
predictTest <- predict(modelGBM, newdata=testing)
print(as.data.frame(predictTest))
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(urlTesting))
dim(testing)
str(testing, list.len=160)
print(testing)
predictTesting3 <- predict(modelRandomF, newdata=testing)
print(as.data.frame(predictTesting3))
predictTesting2 <- predict(modelKNN, testing)
print(as.data.frame(predictTesting2))
# cross validation of GBM
predictGBM <- predict(modelGBM, newdata=tidyCrossVal)
confMatxGBM <-confusionMatrix(predictGBM, tidyCrossVal$classe)
confMatxGBM
# set control
tidyControl <- trainControl(method = "cv", number = 6)
# train GM
modelGBM <- train(classe ~., data=tidyTraining, method="gbm", metric="Kappa", trControl=tidyControl, verbose=FALSE)
str(dataTraining, list.len=160)
# apply Random Forest Model model to testing dataset
predictTest <- predict(modelRandomF, newdata=testing)
# print out prediction
print(as.data.frame(predictTest))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=5, fig.height=4)
options(width = 120)
# Chunk 2: load packages and set seed
# Prepare the R environment by loading required packages
library(plyr)
library(caret)
library(randomForest)
library(gbm)
library(survival)
library(splines)
library(parallel)
library(e1071)
# set seed for reproducibility
set.seed(425)
# Chunk 3: load training data
# Loading Data from url
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining <- read.csv("pml-training.csv", header=TRUE)
# Chunk 4: review dataset
# use "dim" to give brief overveiw of dataset structure
dim(dataTraining)
# Chunk 5: remove number column and remove large NA variables
# remove number column
dataTraining <- dataTraining[,-1]
# Remove varables with NA greater than 90%. "dim" to review datset structure
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dataTraining <- dataTraining[, naVar==FALSE]
dim(dataTraining)
# Chunk 6: remove variables with Near Zero Variance
# remove variables with Near Zero Variance
nearZero <- nearZeroVar(dataTraining)
dataTraining <- dataTraining[, -nearZero]
dim(dataTraining)
# Chunk 7: split dataframe training and for cross-validation
# split dataframe training and for cross-validation.
dataTraining2 <- createDataPartition(y=dataTraining$classe,p=0.7, list=FALSE)
tidyTraining <- dataTraining[dataTraining2,]
tidyCrossVal <- dataTraining[-dataTraining2,]
# check structure of the partitioned datesets.
dim(tidyTraining)
dim(tidyCrossVal)
# Chunk 8: set control and train Random Forest Model
# set a control group
rfControl <- trainControl(method = "oob", number = 4)
# Random forest Model
modelRandomF <- train(classe ~., data=tidyTraining, method="rf", ntree=300, metric="Kappa", trControl=rfControl)
modelRandomF$finalModel
# Chunk 9: cross validation of random forest
# cross validation of random forest model
predictRandomF <- predict(modelRandomF, tidyCrossVal)
confMatxRandomF <-confusionMatrix(predictRandomF, tidyCrossVal$classe)
confMatxRandomF
# Chunk 10: SVM
# train SVM
modelSVM = train(classe ~., data=tidyTraining, method="svmLinear", metric="Kappa")
modelSVM$finalModel
# Chunk 11
# SVM cross validation
predictSVM <- predict(modelSVM, tidyCrossVal)
confMatxSVM <- confusionMatrix(predictSVM, tidyCrossVal$classe)
confMatxSVM
# Chunk 12: train Generalized Boosted Model (GBM)
# set control
gbmControl <- trainControl(method = "repeatedcv")
# train GBM
modelGBM <- train(classe ~., data=tidyTraining, method="gbm", metric="Kappa", trControl=gbmControl, verbose=FALSE)
modelGBM$finalModel
# Chunk 13: cross validation of GBM
# cross validation of GBM
predictGBM <- predict(modelGBM, tidyCrossVal)
confMatxGBM <-confusionMatrix(predictGBM, tidyCrossVal$classe)
confMatxGBM
# Chunk 14: load testing data
# Load test data from URL
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urlTesting, destfile="pml-testing.csv")
testing <- read.csv("pml-testing.csv", header=TRUE)
# Check dimension of testing dataset
dim(testing)
# Chunk 15: apply Random Forest Model to the testing dataset
# apply Random Forest Model model to testing dataset
predictTest <- predict(modelRandomF, newdata=testing)
# print out prediction
print(as.data.frame(predictTest))
# Prepare the R environment by loading required packages
library(plyr)
library(caret)
library(randomForest)
library(gbm)
library(survival)
library(kernlab)
library(splines)
library(parallel)
library(e1071)
# set seed for reproducibility
set.seed(425)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=5, fig.height=4)
options(width = 120)
# Chunk 2: load packages and set seed
# Prepare the R environment by loading required packages
library(plyr)
library(caret)
library(randomForest)
library(gbm)
library(survival)
library(kernlab)
library(splines)
library(parallel)
library(e1071)
# set seed for reproducibility
set.seed(425)
# Chunk 3: load training data
# Loading Data from url
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining1 <- read.csv("pml-training.csv", header=TRUE)
# Chunk 4: review dataset
# use "dim" to give brief overveiw of dataset structure
dim(dataTraining1)
# Chunk 5: remove number column and remove large NA variables
# remove number column
dataTraining <- dataTraining[,-1]
# Remove varables with NA greater than 90%. "dim" to review datset structure
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dataTraining <- dataTraining[, naVar==FALSE]
dim(dataTraining)
str(dataTraining1, list.len=40)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, fig.width=5, fig.height=4)
options(width = 120)
# Chunk 2: load packages and set seed
# Prepare the R environment by loading required packages
library(plyr)
library(caret)
library(randomForest)
library(gbm)
library(survival)
library(kernlab)
library(splines)
library(parallel)
library(e1071)
# set seed for reproducibility
set.seed(425)
# Chunk 3: load training data
# Loading Data from url
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urlTraining, destfile="pml-training.csv")
dataTraining1 <- read.csv("pml-training.csv", header=TRUE)
# Chunk 4: review dataset
# use "dim" to give brief overveiw of loaded dataset structure
dim(dataTraining1)
# Chunk 5: remove number column and remove large NA variables
# remove number column -
dataTraining <- dataTraining1[,-1]
# Remove varables with NA greater than 90%. "dim" to review datset structure
naVar <- sapply(dataTraining, function(x) mean(is.na(x))) > 0.90
dataTraining <- dataTraining[, naVar==FALSE]
dim(dataTraining)
